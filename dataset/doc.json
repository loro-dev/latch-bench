{
  "cells": [
    {
      "cellType": "markdown",
      "source": "# **qPCR Analyzer**\n\nLayout to visualize and analyze qPCR data."
    },
    {
      "cellType": "code",
      "source": "from lplots.reactive import Signal\nimport pandas as pd\nfrom pathlib import Path\nimport numpy as np\nimport os\nimport glob\nfrom lplots.widgets.text import w_text_input, w_text_output\nfrom lplots.widgets.ldata import w_ldata_picker\nfrom lplots.widgets.checkbox import w_checkbox\nfrom lplots.widgets.select import w_select\nfrom lplots.widgets.multiselect import w_multi_select\nfrom lplots.reactive import Signal\nfrom latch.ldata.path import LPath\nimport os\nimport datetime\n\nqpcr_data_signal = Signal(None)\ndelta_ct_option_signal = Signal(None)\ncondition_column_value = None\nrun_name_signal = Signal(None)\noutdir_signal = Signal(None)\noutput_ready_signal = Signal(None)\n\nwell_col_signal = Signal(None)\ncq_col_signal = Signal(None)\ntarget_col_signal = Signal(None)\nhk_signal = Signal(None)\ntreat_col_signal = Signal(None)\ncontrol_signal = Signal(None)\ngroup_col_signal = Signal(None)\n\n\nw_text_output(\n  content=\"\"\"\n## Import qPCR Data\nTo start, either import your own qPCR data or check the **Use Test Data** box to use a test dataset.\n\nFor uploading your own data, please provide your qPCR machine readout file. This file often contains columns such as _Cq_, _Target_, _Well_.\"\"\"\n)\n\ndef demo_dataset():\n  demo_latch_path = LPath(\"latch:///qPCR_Demo/output.csv\")\n\n  try:\n    a = demo_latch_path.size()\n    print(a)\n\n  except:\n    local_dir = \"/root/qPCR_Demo/output.csv\"\n    os.system(\n        f\"/opt/mamba/envs/plots-faas/bin/aws s3 cp s3://latch-public/test-data/22353/output.csv {local_dir}\"\n    )\n\n    demo_latch_path.upload_from(local_dir)\n\n    print(\"Downloaded\")\n\ndef find_best_match(columns, search_str):\n    # Check for exact match first\n    if search_str in columns:\n        return search_str\n    \n    # Find the best partial match with at least 2 matching starting letters\n    best_match = max(\n        (col for col in columns if col.startswith(search_str[:2])),\n        key=lambda col: sum(c1 == c2 for c1, c2 in zip(col, search_str)),\n        default=None\n    )\n    \n    return best_match\n\ndef create_comparison_table(groups, control, experiment):\n    # data = {'Group': groups, 'Example Comparison': [f\"{group} vs. {control} (CONTROL)\" for group in groups]}\n    # df = pd.DataFrame(data)\n    # return df.to_markdown(index=False)\n    if experiment is None:\n      header = \"| Group   | Example Comparison        |\\n|:--------|:--------------------------|\\n\"\n      rows = [f\"| {group}     | {group} vs. {control} (CONTROL)     |\\n\" for group in groups]\n    else:\n      experimental_condition_str = \", \".join(experiment)\n      sample_experiment = experiment[0]\n      header = \"| Group   | Experimental Condition        | Example Comparison                      |\\n|:--------|:-------------------|:----------------------------------------|\\n\"\n      rows = [f\"| {group}     | {experimental_condition_str}     | {group} {sample_experiment} vs. {group} {control} (CONTROL)     |\\n\" for group in groups]  \n    return header + ''.join(rows)\n\n\n# Download file if none exists\ndef download_file_if_not_exists(remote_lpath):\n    file_name = remote_lpath.path.split(\"/\")[-1]\n    pattern = f\"/root/.latch/lpath/*/{file_name}\"\n    matching_files = glob.glob(pattern)\n  \n    if matching_files:\n        max_file_path = max(matching_files, key=lambda x: int(x.split('/')[-2]))\n        print(\"File path with the highest number:\", max_file_path)\n        return max_file_path\n      \n    else:\n        print(\"No files found matching the pattern.\")\n        return remote_lpath.download()\n\ndef sheet_to_well_plate_map(df, idx_to_row_id):\n  well_plate_dict = {}\n  for idx, row in df.iterrows():\n    for col in df.columns:\n      try:\n        well_id = f\"{idx_to_row_id[idx]}{col}\"\n      except KeyError:\n        raise ValueError(f\"Invalid well row {idx}. Make sure your metadata sheet has less than or equal to 16 rows.\")\n      well_plate_dict[well_id] = row[col]\n  return well_plate_dict\n\ndef remove_surrounding_quotes(s):\n    if isinstance(s, str):\n        if (s.startswith('\"') and s.endswith('\"')) or (s.startswith(\"'\") and s.endswith(\"'\")):\n            return s[1:-1]\n    return s\n\n    # Check for exact match first\n    if search_str in columns:\n        return search_str\n    \n    # Find the best partial match with at least 2 matching starting letters\n    best_match = max(\n        (col for col in columns if col.startswith(search_str[:2])),\n        key=lambda col: sum(c1 == c2 for c1, c2 in zip(col, search_str)),\n        default=None\n    )\n    \n    return best_match\n\ndef import_data(use_test_data):\n  demo_dataset()\n  \n  # Set empty defaults for current columns and sheets selected \n  current_columns = []\n  sheets_added = []\n  original_columns = []\n  imported_qpcr_data = None\n  \n  ######################\n  # Machine Data Sheet #\n  ######################\n\n  if use_test_data.value is True:\n    well_def = \"latch:///qPCR_Demo/output.csv\"\n  else:\n    well_def = None\n  well_result_lpath = w_ldata_picker(\n    label=\"qPCR Machine Output\", \n    required=True,\n    default=well_def,\n    appearance={\n    \"detail\": \"(.csv, .xlsx)\"\n    }\n  )\n  \n  well_opt = []\n  if well_result_lpath.value is None:\n    print(\"Please fill out the value\")\n    #well_result_lpath._state[\"appearance\"] = {\"detail\": \"(.csv, .xlsx)\", \"error_text\": \"* Required\", \"placeholder\": \"Select a file...\"}\n  else:\n    well_result_file = download_file_if_not_exists(well_result_lpath.value)\n    print(well_result_file)\n  \n    # Check if file is an excel file\n    if \".xlsx\" in str(well_result_file):\n      imported_qpcr_data = pd.ExcelFile(str(well_result_file))    \n      selected_sheet = w_select(label=\"Select results sheet from Excel file\", options=imported_qpcr_data.sheet_names).value\n      \n      # skiprows = w_text_input(label=\"Number of rows to skip (to remove machine metadata):\", default=\"24\").value\n      skiprows = 24\n      \n      if skiprows is not None and selected_sheet is not None:\n        imported_qpcr_data = pd.read_excel(\n          str(well_result_file), \n          sheet_name=selected_sheet, \n          skiprows=int(skiprows)\n        )\n        \n      well_opt = imported_qpcr_data.keys() if selected_sheet is not None else []\n        \n    # File is a CSV\n    else:\n      imported_qpcr_data = pd.read_csv(well_result_file)\n      well_opt = imported_qpcr_data.keys() if imported_qpcr_data is not None else []\n\n  # Set column values\n  well_opt_placeholder = \"Select a columnâ€¦\" if imported_qpcr_data is not None else \"Provide a readout fileâ€¦\"\n\n  if use_test_data.value is True:\n    well_col_def = \"Well Position\"\n  else:\n    well_col_def = None\n  well_column = w_select(\n    label=\"Well column\", \n    required=imported_qpcr_data is not None,\n    options=well_opt,\n    default=well_col_def,\n    readonly=imported_qpcr_data is None,\n    appearance={\n      \"detail\": \"(ex: A1)\",\n      \"placeholder\": well_opt_placeholder\n    }\n  )\n\n  # Add error checking for the Well column to make sure it includes A1, A2, A3\n  if imported_qpcr_data is not None and well_column.value is not None:\n    well_col_signal(well_column.value)\n    if not \"A1\" in list(imported_qpcr_data[well_column.value]):\n      w_text_output(\n        content=\"The column you selected doesn't contain well IDs (e.g. A1).\",\n        appearance={\n          \"message_box\": \"warning\",\n        }\n      )\n\n  try:\n    original_columns = imported_qpcr_data.columns\n  except:\n    return None, None, None, None\n  \n  if (well_column.value is not None):  \n    current_columns = [well_column.value]\n  w_text_output(content=\"\"\"----\"\"\")\n  \n  #############################\n  # Metadata Sheet (Optional) #\n  #############################\n  \n  w_text_output(content=\"\"\"\n  If your machine readout file doesn't contain experimental metadata you can provide it using an Excel Template file. [ğŸ“„ Download Template â†“](https://latch-public.s3.us-west-2.amazonaws.com/plot-templates/qpcr/latch_qPCR_metadata.xlsx)\n  \"\"\")\n  \n  use_metadata = w_checkbox(\n    label=\"Use template file to provide experimental metadata\", \n    default=False\n  )\n  \n  if use_metadata.value is False:\n    well_plate_metadata_lpath = w_ldata_picker(\n    label=\"Well Plate Metadata\", \n    readonly=True,\n    appearance={\n      \"detail\": \"(.xlsx)\"\n    }\n  )\n    return imported_qpcr_data, current_columns, sheets_added, well_column\n  \n  well_plate_metadata_lpath = w_ldata_picker(\n    label=\"Well Plate Metadata\", \n    required=True,\n    appearance={\n      \"detail\": \"(.xlsx)\"\n    }\n  )\n\n  if well_plate_metadata_lpath.value is None:\n    print(\"No well plate metadata provided.\")\n  else:\n    if well_plate_metadata_lpath.value != \"\":\n\n      use_metadata_sheet = True\n      well_plate_metadata_file = download_file_if_not_exists(well_plate_metadata_lpath.value)\n      well_plate_metadata_df = pd.read_excel(well_plate_metadata_file, sheet_name=None)\n      assert type(well_plate_metadata_df) is dict\n      selected_metadata_variables = w_multi_select(label=\"Select sheets to combine with qPCR machine data\", options=well_plate_metadata_df.keys(), default=list(well_plate_metadata_df.keys()))\n      if selected_metadata_variables.value is None or selected_metadata_variables.value == []:\n        imported_qpcr_data = imported_qpcr_data[original_columns]\n        return imported_qpcr_data, current_columns, sheets_added, well_column\n  \n  if well_plate_metadata_lpath.value is None:\n    return imported_qpcr_data, current_columns, sheets_added, well_column\n  \n  if use_metadata_sheet is False:\n    return imported_qpcr_data, current_columns, sheets_added, well_column\n  \n  if None not in [well_column.value, selected_metadata_variables.value]:\n    idx_to_row_id = {\n      0: \"A\",\n      1: \"B\",\n      2: \"C\",\n      3: \"D\",\n      4: \"E\",\n      5: \"F\",\n      6: \"G\",\n      7: \"H\",\n      8: \"I\",\n      9: \"J\",\n      10: \"K\",\n      11: \"L\",\n      12: \"M\",\n      13: \"N\",\n      14: \"O\",\n      15: \"P\",\n  }\n  \n  sheets_added = selected_metadata_variables.value\n  if sheets_added == []:\n    imported_qpcr_data = imported_qpcr_data[original_columns]\n  \n  for sheet_name, df in well_plate_metadata_df.items():\n    \n    if selected_metadata_variables.value and sheet_name not in selected_metadata_variables.value:\n      continue\n    \n    assert \"Well\" in df.columns, \"Well column missing from excel sheet. Reach out to an engineer at Latch to ensure your metadata sheet is formatted correctly.\"\n    df = df.drop(columns=[\"Well\"])\n    imported_qpcr_data[sheet_name] = imported_qpcr_data[\"Well\"].map(sheet_to_well_plate_map(df, idx_to_row_id))\n  \n  #Text to show if sheets are added\n  if len(sheets_added) > 0:\n    sheets_added_display = f\"Added {len(sheets_added)} sheets: {', '.join(sheets_added)}\"\n    \n  if len(sheets_added) == 0:\n   sheets_added_display = f\"Added {len(sheets_added)} sheets\"\n  \n  w_text_output(\n      content=f\"\"\"\n  Machine data imported successfully.\n  \n  {sheets_added_display}\n      \"\"\",\n      appearance={\n        \"message_box\": \"success\",\n      },\n    )\n  return imported_qpcr_data, current_columns, sheets_added, well_column\n\n\nuse_test_data = w_checkbox(label=\"Use test data\", default=False)\n\nimported_data, current_columns, sheets_added, well_column = import_data(use_test_data)\n\nprint(imported_data)\n\nw_text_output(content=\"\"\"\n## Experiment Set-up\n\nWe are going to specify the experimental variables required to calculate âˆ†Cq, âˆ†âˆ†Cq, and fold change.\n\"\"\")\n\ndef make_line():\n  w_text_output(content=\"-----\")\n\nqpcr_data = imported_data\n\ntry: \n  column_opts = qpcr_data.columns\n  column_select_placeholder = \"Select a columnâ€¦\"\n  prev_completed = True\n\nexcept: \n  column_opts = []\n  column_select_placeholder = \"Provide a readout fileâ€¦\"\n  prev_completed = False\n\n# Cq Column\ncq_column = w_select(\n  label=\"Cq column\",  \n  options=column_opts,\n  readonly=not prev_completed,\n  default=find_best_match(qpcr_data.columns, \"Cq\") if qpcr_data is not None else None,\n  required=prev_completed,\n  appearance={\n    \"placeholder\": column_select_placeholder,\n  }\n)\n\n# Remove Undetermined rows\ntry:\n  current_columns.append(cq_column.value)\n  cq_col_signal(cq_column.value)\nexcept:\n  print(\"Removed\")\n\n\n# Target Column\ntarget_column = w_select(\n  label=\"Target column\", \n  default=find_best_match(qpcr_data.columns, \"Target\") if qpcr_data is not None else None,\n  options=column_opts,\n  required=prev_completed,\n  readonly=not prev_completed,\n  appearance={\n    \"description\": \"This column contains your target and housekeeping genes.\",\n    \"placeholder\": column_select_placeholder,\n  },\n)\n\ntry:\n  housekeeping_options = qpcr_data[target_column.value].unique()\n  target_col_signal(target_column.value)\n  housekeeping_placeholder = \"Select geneâ€¦\"\n  \nexcept:\n  housekeeping_options = []\n  housekeeping_placeholder = \"Select a target column firstâ€¦\"\n\nif use_test_data.value is True:\n  hk_def = [\"B2M\"]\nelse:\n  hk_def = None\nhousekeeping_gene = w_multi_select(\nlabel=\"Housekeeping gene(s)\", \noptions=housekeeping_options,\nreadonly=not prev_completed,\nrequired=prev_completed,\ndefault=hk_def,\nappearance={\n  \"placeholder\": housekeeping_placeholder,\n  },\n)\n\nif housekeeping_gene.value is not None:\n  hk_signal(housekeeping_gene.value)\n\ntry: \n  column_opts = qpcr_data.columns\n  column_select_placeholder = \"Select a columnâ€¦\"\n\nexcept: \n  column_opts = []\n  column_select_placeholder = \"Provide a readout fileâ€¦\"\n\nif use_test_data.value is True:\n  cond_def = \"dose_name\"\nelse:\n  cond_def = None\ncondition_column = w_select(\n  label=\"Experimental condition column\",\n  options=column_opts,\n  readonly=not prev_completed,\n  required=prev_completed,\n  default=cond_def,\n  appearance={\n    \"placeholder\": column_select_placeholder,\n    \"description\": \"\"\"\n    The experimental condition variable stores the control condition for calculating ğš«ğš«Ct.\"\n    \"\"\"\n  },\n)\n\nif condition_column.value is None:\n  control_val = w_select(\n    label=\"Control condition\",\n    appearance={\n      \"description\": \"Often the untreated condition, vehicle, or another condition specific to your experiment.\"\n    },\n    readonly=True,\n    options=[],\n  )\nelse:\n  treat_col_signal(condition_column.value)\n  qpcr_data = qpcr_data[~pd.isna(qpcr_data[condition_column.value])]\n  if use_test_data.value is True:\n    control_def = \"DMSO\"\n  else:\n    control_def = None\n  control_val = w_select(\n    label=\"Control condition\", \n    options=qpcr_data[condition_column.value].unique(),\n    default =control_def,\n    appearance={\n      \"placeholder\": \"Select conditionâ€¦\",\n      \"description\": \"Often the untreated condition, vehicle, or another condition specific to your experiment.\"\n    }\n    )\n  \ngroup_column = None\nif use_test_data.value is True:\n  group_def = True\nelse:\n  group_def = False\n\ngrouping_checkbox = w_checkbox(label=\"Add optional Group column\", default=group_def)\nif grouping_checkbox.value is True:\n  if use_test_data.value is True:\n    group_col_def = \"drug_name\"\n  else:\n    group_col_def = None\n  \n  group_column = w_select(\n    label=\"Group column\", \n    options=column_opts,\n    required=prev_completed,\n    readonly=not prev_completed,\n    default=group_col_def,\n    appearance={\n      \"placeholder\": column_select_placeholder,\n      # \"description\": \"\"\"\n      # A group variable is a categorical variable used to organize data into distinct subsets, ensuring comparisons are made only within these subsets. For example, in an experiment repeated for multiple tissues using the same treatments, the group variable should be set to \"Tissue\" and the condition variable to \"Treatment\". This ensures that treatments are compared only within the same tissue type.\n      # \"\"\"\n    },\n  ).value\n\n  if group_column is not None:\n    current_columns.append(group_column)\n    group_col_signal(group_column)\nelse:\n  if condition_column.value is not None:\n    current_columns.append(condition_column.value)\n    group_column = condition_column.value\n\n\nmake_line()\n  \ntry:\n  current_columns = list(set(current_columns))\nexcept:\n  current_columns = []\n\n# Join additional columns\nadditional_columns = w_multi_select(\n  label=\"Add additional columns to include\", \n  options=[x for x in column_opts if ((x not in current_columns))], \n  default=sheets_added,\n  appearance={\n    \"help_text\": \"If no options appear, it means all columns are already included.\",\n  },\n)\ntry:\n  final_columns = current_columns + additional_columns.value\nexcept:\n  final_columns = []\n\n\nw_text_output(content=\"\"\"\n## Output Results\nSelect a directory to save your outputs to\n\"\"\")\n\n\nrun_name = w_text_input(label=\"Run Name:\", appearance={\n      \"placeholder\": \"Add a run name...\",\n    }, default=None)\noutput_dir = w_ldata_picker(\n  label=\"Select output directory\", \n  required=True,\n  default=\"latch:///qpcr_outputs/\"\n)\n\nif run_name.value is not None:\n  run_name_signal(run_name.value)\nif output_dir.value is not None:\n  outdir_signal(output_dir.value)\n\noutput_ready = w_checkbox(label=f\"Check if output folder looks correct: \\n {output_dir.value.path}{run_name.value}\", default=False)\noutput_ready_signal(output_ready.value)\n\nif not prev_completed:\n  exit()\n\nif None not in [well_column.value, cq_column.value, group_column, target_column.value]:\n  current_columns = [well_column.value, cq_column.value, target_column.value, group_column]\n  \n  if additional_columns.value is not None:\n    final_columns = current_columns + additional_columns.value\n    \n  else:\n    final_columns = current_columns\n\n# String leading / trailing spaces\nfor col in qpcr_data.columns:\n  print(col)\n  if pd.api.types.is_string_dtype(qpcr_data[col].dtype):\n    try:\n      qpcr_data[col].str.strip()\n    except:\n      qpcr_data[col] = qpcr_data[col]\n\n# Rename columns\nif None not in [well_column.value, cq_column.value, group_column, target_column.value]:\n  condition_column_value = condition_column.value\n  if condition_column_value is not None:\n    final_columns.append(condition_column_value)\n  qpcr_data = qpcr_data[list(set(final_columns))]\n  \n  if condition_column.value is not None:\n      w_text_output(content=f\"\"\"\n  ### Preview Study Design\n  Inspect the table below to see if groupings make sense.\n        \"\"\")\n      ###################\n      # Create table preview:\n      if grouping_checkbox.value is True:\n        group_values = qpcr_data[group_column].unique()\n        experimental_values = qpcr_data[condition_column_value].unique()\n        markdown_table = create_comparison_table(group_values, control_val.value, experimental_values)\n      elif condition_column_value is not None:\n        group_values = qpcr_data[condition_column_value].unique()\n        markdown_table = create_comparison_table(group_values, control_val.value, None)\n      else:\n        markdown_table = None\n      if markdown_table is not None:\n        w_text_output(content=f\"\"\"\n  {markdown_table}\n        \"\"\")\n\n\n\n# Remove undetermined data\nqpcr_data = qpcr_data[qpcr_data['Cq'] != \"Undetermined\"]\n\n# Remove quotations from columns\nfor col in qpcr_data.select_dtypes(include=['object']).columns:\n  qpcr_data[col] = qpcr_data[col].apply(remove_surrounding_quotes)\n\nqpcr_data_signal(qpcr_data)\nqpcr_data_plotting = qpcr_data.rename(columns={well_column.value: 'Well', cq_column.value: 'Cq', target_column.value: 'Target'})\n\n\n\n\n\n",
      "metadata": {
        "transformId": "7074",
        "stale": false
      },
      "language": "python"
    },
    {
      "plotId": "6990",
      "cellType": "plot",
      "metadata": {
        "controllingViewerId": null,
        "viewerId": null,
        "display": {
          "height": 556.65625
        }
      }
    },
    {
      "cellType": "code",
      "source": "from lplots.widgets.text import w_text_input, w_text_output\n\nif \"delta_ct_signal\" not in globals():\n  delta_ct_signal = Signal([])\n\nw_text_output(content=\"\"\"\n## ğš«Cq Calculation\n\nWe are now going to calculate Delta Ct (```ğš«Cq```) by subtracting the ```Cq``` values of the housekeeping gene from our that of the target genes.\"\"\")\n\nw_text_output(content=\"\"\"\n\n\nThe ```Cq``` value of the housekeeping gene is subtracted from the ```Cq``` value of the target genes.\n\nThe ```ğš«Cq``` value for each target gene can be defined as:\n\n$$ \\Delta {Cq}_{target} = {Cq}_{{target}} - {Cq}_{{housekeeping}} $$\n\nHit the ```Run``` button to generate results, after removing wells above that cause errors.\n\n\"\"\")\n\ndef df_column_switch(df, column1, column2):\n  i = list(df.columns)\n  a, b = i.index(column1), i.index(column2)\n  i[b], i[a] = i[a], i[b]\n  df = df[i]\n  return df\n\ndef calculate_delta_ct(delta_cq_df, delta_ct_option, housekeeping_gene):\n  import pandas as pd\n  from pathlib import Path\n  import os\n  import glob\n\n  delta_ct_option = len(delta_cq_df[delta_cq_df[well_column.value] == delta_cq_df[well_column.value].iloc[0]][target_column.value].unique()) > 1\n\n  targets = list(delta_cq_df[target_col_signal()].unique())\n  if delta_ct_option is False:\n    delta_cq_df = delta_cq_df.drop(well_col_signal(), axis=1)\n\n  targets = [t for t in targets if t not in housekeeping_gene]\n  delta_cq_df[cq_col_signal()] = pd.to_numeric(delta_cq_df[cq_col_signal()])\n\n  _ct_df = {}\n  _ct_df_T = {}\n\n  for target in targets:\n    for hk_gene in housekeeping_gene:\n      df_name = f'ğš«Cq_{target}_{hk_gene}'\n      data = delta_cq_df[(delta_cq_df[target_col_signal()] == target) | (delta_cq_df[target_col_signal()] == hk_gene)]\n      data = data[data[cq_col_signal()] != \"Undetermined\"]\n      print(data)\n      print(data['drug_name'].values)\n      data = data.pivot_table(\n        index=[col for col in data.columns if col not in set([target_col_signal(), cq_col_signal()])],\n        columns=target_col_signal(),\n        values=cq_col_signal()\n      ).reset_index()\n      data['ğš«Cq'] = data[target] - data[hk_gene]\n      data = df_column_switch(data, target, hk_gene)\n    \n      _ct_df[df_name] = pd.DataFrame(data)\n  \n      data_T = data.drop(hk_gene, axis=1)\n      data_T[cq_col_signal()] = data_T[target]\n      data_T[target_col_signal()] = target\n      data_T[\"Housekeeping Gene\"] = hk_gene\n  \n      _ct_df_T[df_name] = pd.DataFrame(data_T)\n\n  for name, df in _ct_df.items():\n    locals()[name] = df\n    \n  delta_cq_df = pd.concat(_ct_df_T.values(), ignore_index=True)\n  delta_cq_df = df_column_switch(delta_cq_df, \"Cq\", \"ğš«Cq\")\n  delta_cq_df = delta_cq_df.drop(targets, axis=1)\n\n  bullet_points = [gene for gene in _ct_df.keys()]\n\n  return _ct_df, delta_cq_df, bullet_points\n\ntry:\n  pre_delta_cq_df = globals()['df_1834']\n  print(\"HIII\")\nexcept:\n  print(\"Skipping filtered dataframe retrieval\")\n  pre_delta_cq_df = qpcr_data_signal()\n\nif pre_delta_cq_df is None:\n  w_text_output(\ncontent=f\"\"\"\nWarning: Import your data.\n\"\"\",\nappearance={\n\"message_box\": \"warning\",\n  })\n  exit()\n\nif hk_signal() is None:\n  exit()\n\nif pre_delta_cq_df.isnull().values.any():\n  missing_indices = pre_delta_cq_df[pre_delta_cq_df.isnull().any(axis=1)].index\n  missing_indices = pre_delta_cq_df.loc[missing_indices, well_col_signal()].tolist()\n  missing_indices = '\\n'.join(missing_indices)\n  w_text_output(\ncontent=f\"\"\"\nError in input data, Cq values are null in wells: \n{missing_indices}. Filter out null rows in the cell above and re-run this cell. \n\"\"\",\nappearance={\n\"message_box\": \"danger\",\n  })\n  try:\n    del locals()['pre_delta_cq_df']\n  except KeyError:\n    pass\n  exit()\n\nresult_tables, delta_cq_df, bullet_points = calculate_delta_ct(pre_delta_cq_df, delta_ct_option_signal(), hk_signal())\ndelta_ct_signal(delta_cq_df)\n\nexport_results = w_checkbox(label=\"Output intermediate results tables\", default=False)\n\nif export_results.value is True:\n  for name, df in result_tables.items():\n    locals()[name] = df\n    try:\n      del locals()['df']\n    except KeyError:\n      pass\n\nbullet_points = [name.split('_')[1:] for name in bullet_points]\n\n# Create markdown table\ntable_md = \"| Target | Housekeeping Gene |\\n| --- | --- |\\n\"\nfor target, hk_gene in bullet_points:\n    table_md += f\"| {target} | {hk_gene} |\\n\"\n\nw_text_output(content=f\"\"\"\n### Results\nGreat! If you look below, you will see that a table containing the groups created:\n  {table_md} \\n\nYou can view a merged table with all non-housekeeping gene targets by checking out the ```delta_cq_df``` table below.\n  \"\"\") ",
      "metadata": {
        "transformId": "7072",
        "stale": false
      },
      "language": "python"
    },
    {
      "cellType": "code",
      "source": "import warnings\nimport pandas as pd\n\nwarnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n\nfrom lplots.widgets.text import w_text_input, w_text_output\n\nfrom lplots.reactive import Signal\n\nif \"delta_delta_cq_df_signal\" not in globals():\n  delta_delta_cq_df_signal = Signal(delta_ct_signal())\n\nremove_outliers_signal = Signal(False)\n\ndef calc_delta_delta_ct(df_group):\n  df_group[\"Relative Expression\"] = pd.to_numeric(2 ** (-df_group['ğš«Cq']))\n  df_group['Mean Control ğš«Cq'] = df_group[(df_group[treat_col_signal()] == control_val.value)][\"ğš«Cq\"].mean()\n  df_group[\"ğš«ğš«Cq\"] = df_group[\"ğš«Cq\"] - df_group[\"Mean Control ğš«Cq\"]\n  df_group['Fold Change'] = 2 ** (-df_group['ğš«ğš«Cq'])\n  df_group[\"Percent Expression\"] = (df_group[\"Fold Change\"]*100)\n  df_group[\"Percent Repression\"] = 100-(df_group[\"Fold Change\"]*100)\n  return df_group\n\nw_text_output(content=\"\"\"\n## ğš«ğš«Cq Calculation\n\nNow we are going to calculate ğš«ğš«Cq. This will be calculated using the value you selected earlier as your control condition.\"\"\")\n\n\ndelta_cq_df = delta_ct_signal()\n\nif len(delta_cq_df) == 0:\n  w_text_output(\ncontent=f\"\"\"\nWarning: Fix error in ğš«Cq calculation cell or complete earlier steps.\n\"\"\",\nappearance={\n\"message_box\": \"warning\",\n  })\n  exit()\n\nif treat_col_signal() is None:\n  exit()\n\ndef calculate_delta_delta_ct(control_column_value, control_val):\n  delta_cq_df = delta_ct_signal() \n  grouping_columns = [target_col_signal(), treat_col_signal()]\n  if group_col_signal() is not None:\n    grouping_columns.append(group_col_signal())\n  \n  groups = []\n  group_text = []\n  is_tuple = False\n  \n  # Create Groups\n  if len(grouping_columns) == 3:\n    is_tuple = True\n    for x in delta_cq_df[group_col_signal()].unique():\n      for i in delta_cq_df[target_col_signal()].unique():\n          groups.append((x, i))\n          group_text.append(f\"Group: {x} | Target: {i} | Control: {treat_col_signal()} = {control_val.value}\")\n  else:\n    for i in delta_cq_df[target_col_signal()].unique():\n      groups.append(i)\n      group_text.append(f\"Target: {i} | Control: {treat_col_signal()} = {control_val.value}\")\n  \n  \n  # Create result dataframes\n  if len(groups) > 0:\n    ctrl_dataframes = {}\n    dataframes = {}\n    \n    delta_cq_df_temp = delta_cq_df\n    hk_genes = delta_cq_df[\"Housekeeping Gene\"].unique()\n    \n\n    for hk in hk_genes:\n      delta_cq_df = delta_ct_signal()\n      delta_cq_df = delta_cq_df[delta_cq_df[\"Housekeeping Gene\"] == hk]\n      # delta_cq_df = delta_cq_df.drop([\"Housekeeping Gene\"], axis=1)\n  \n      for i in range(len(groups)):\n        if is_tuple:\n          # Control DF\n          df_name = f\"ctrl_{groups[i][0]}_{hk}_{groups[i][1]}\"\n          data = delta_cq_df[(delta_cq_df[group_col_signal()] == groups[i][0]) & (delta_cq_df[target_col_signal()] == groups[i][1])]\n          data = data[(data[treat_col_signal()] == control_val.value)]\n          data[\"Group\"] = f\"{groups[i][0]}_{groups[i][1]}\"\n          data['Mean Control ğš«Cq'] = data[(data[treat_col_signal()] == control_val.value)][\"ğš«Cq\"].mean()\n          ctrl_dataframes[df_name] = pd.DataFrame(data)\n    \n          # Delta Delta DF\n          df_name = f\"ğš«ğš«Cq_{groups[i][0]}_{hk}_{groups[i][1]}\"\n          data = delta_cq_df[(delta_cq_df[group_col_signal()] == groups[i][0]) & (delta_cq_df[target_col_signal()] == groups[i][1])]\n          data = calc_delta_delta_ct(data)\n          dataframes[df_name] = pd.DataFrame(data)\n          \n        else:\n          # Control DF\n          df_name = f'ctrl_{groups[i]}_{hk}'\n          data = delta_cq_df[delta_cq_df[target_col_signal()] == groups[i]]\n          data = data[(data[treat_col_signal()] == control_val.value)]\n          data[\"Group\"] = f\"{groups[i]}\"\n          data['Mean Control ğš«Cq'] = data[\"ğš«Cq\"].mean()\n          print(data[[\"Group\",\"ğš«Cq\",\"Mean Control ğš«Cq\"]])\n          ctrl_dataframes[df_name] = pd.DataFrame(data)\n    \n          # Delta Delta DF\n          df_name = f'ğš«ğš«Cq_{groups[i]}_{hk}'\n          data = delta_cq_df[delta_cq_df[target_col_signal()] == groups[i]]\n          data = calc_delta_delta_ct(data)\n          dataframes[df_name] = pd.DataFrame(data)\n  \n    for name, df in ctrl_dataframes.items():\n        locals()[name] = df\n    for name, df in dataframes.items():\n        locals()[name] = df\n    \n    control_df = pd.concat(ctrl_dataframes.values(), ignore_index=True)\n    delta_delta_cq_df = pd.concat(dataframes.values(), ignore_index=True)\n    group_bullets = '\\n'.join([f'* ```{g}```' for g in group_text])\n    result_bullets = [g for g in list(dataframes.keys())]\n\n    return delta_delta_cq_df, dataframes.items(), group_bullets, result_bullets, grouping_columns, control_df\n\n\ndelta_delta_cq_df, result_dfs, group_bullets, result_bullets, grouping_columns, controls_df = calculate_delta_delta_ct(treat_col_signal(), control_val)\n\n# for name, df in result_dfs:\n#   locals()[name] = df\n#   try:\n#     del df\n#   except:\n#     print(\"Skip\")\ndelta_delta_cq_df_signal(delta_delta_cq_df)\ndelta_delta_cq_df_plotting = delta_delta_cq_df.rename(columns={treat_col_signal(): 'Treatment'})\nw_text_output(content=f\"\"\"\n### Groups\n\nğš«ğš«Cq will be calculated in the following groups:\n{group_bullets} \\n\n\n### Controls\n\nWe start by getting the average ğš«Cq value of the control condition in every group. You can navigate to the ```control_table``` to see all the replicates that will be used as controls.\n\n</n>\n\n### Results\n\nThe ```Mean Control ğš«Cq``` column for each group will be subtracted from the ğš«Cq of each biological replicate:\"\"\")\n\nw_text_output(content=\"\"\"\n$$\\Delta\\Delta {Cq} = \\Delta {Cq} - {Mean Control} \\Delta {Cq}$$\n\"\"\")\n\nw_text_output(content=f\"\"\"\nInspect the ```delta_delta_cq_df``` table to view all results. You can see the new ```ğš«ğš«Cq``` column and other statistics columns in this created dataframe. \n\"\"\")\n\n####################\n# Save output table\nlatch_path = outdir_signal()\nrun = run_name_signal()\nif latch_path is None or run is None or output_ready_signal() is False:\n  exit()\nos.makedirs(f\"./{run}\", exist_ok=True) \ndelta_delta_cq_df.to_csv(f\"./{run}/results.csv\")\nlatch_path.upload_from(f\"./{run}\")\n\n",
      "metadata": {
        "transformId": "7071",
        "stale": false
      },
      "language": "python"
    },
    {
      "plotId": "8189",
      "cellType": "plot",
      "metadata": {
        "controllingViewerId": null,
        "viewerId": null
      }
    },
    {
      "cellType": "code",
      "source": "def f():\n    from typing import Union, List\n    import numpy as np\n    from scipy.stats import t\n\n    from lplots.widgets.text import w_text_input, w_text_output\n    from lplots.widgets.select import w_select\n    from lplots.widgets.multiselect import w_multi_select\n    from lplots.widgets.dataframe import w_dataframe_picker\n\n    df_picker = w_dataframe_picker(label=\"Input data\", \n                                   appearance={\n    \"help_text\": \"Select the table that you would like to remove outliers for (likely delta_ct_df or delta_delta_ct_df).\"\n    })\n  \n    df = df_picker.value\n\n    cols = df.columns if df is not None else []\n    numeric_cols = df.select_dtypes(include=\"number\").columns if df is not None else [\"ğš«Ct\"]\n\n    measurement_col = w_select(\n        label=\"Measurement\",\n        options=numeric_cols,\n        default=numeric_cols[0] if len(numeric_cols) > 0 else None,\n        appearance={\"help_text\": \"Select the metric outliers will be removed for.\"}\n    ).value\n\n    grouping_columns = w_multi_select(\n        label=\"Group by (Optional)\", options=cols, default=[],\n        appearance={\"help_text\": \"Add columns here if you want to remove outliers within specified groups.\"}\n    ).value\n\n    outlier_method = w_select(\n        label=\"Select outlier removal method:\",\n        options=[\"Grubb's\", \"Standard Deviation\"],\n        default=\"Grubb's\",\n    ).value\n\n    if (\n        df is None\n        or measurement_col is None\n        or grouping_columns is None\n        or outlier_method is None\n    ):\n        return\n\n    # https://github.com/maximtrp/scikit-posthocs/blob/3403b677fbdfad1f46c6470260b229e27f63c4af/scikit_posthocs/_outliers.py#L69\n    def outliers_grubbs(x: np.ndarray, alpha: float = 0.05) -> Union[np.ndarray, bool]:\n        res = np.zeros(x.shape)\n\n        dev = np.abs(x - np.mean(x))\n        val = np.max(dev)\n        ind = np.argmax(dev)\n\n        G = val / np.std(x, ddof=1)\n        N = len(x)\n        T = t.ppf(1 - alpha / (2 * N), N - 2) ** 2\n        result = G > (N - 1) / np.sqrt(N) * np.sqrt(T / (N - 2 + T))\n\n        if result:\n            np.put(res, ind, 1)\n\n        return res\n\n    res = df.copy()\n\n    if outlier_method == \"Standard Deviation\":\n        stdev_distance_w = w_text_input(\n            label=\"Remove outliers that are this many standard deviations away:\",\n            default=\"2\",\n        )\n        stdev_distance = stdev_distance_w.value\n\n        if stdev_distance == \"\":\n            stdev_distance_w._state[\"appearance\"] = {\"error_text\": \"Required\"}\n            return\n\n        try:\n            stdev_thres = float(stdev_distance)\n        except ValueError:\n            stdev_distance_w._state[\"appearance\"] = {\"error_text\": \"Invalid number\"}\n            return\n\n        if len(grouping_columns) > 0:\n            avg_df = (\n                res.groupby(grouping_columns, as_index=False)[measurement_col]\n                .agg([\"mean\", \"std\"])\n                .rename(columns={\"mean\": \"PE_mean\", \"std\": \"PE_std\"})\n            )\n            res = res.merge(avg_df, how=\"inner\", on=grouping_columns)\n\n            mask = (res[measurement_col] - res[\"PE_mean\"]) > stdev_thres * res[\"PE_std\"]\n        else:\n            mean = res[measurement_col].mean()\n            std = res[measurement_col].std()\n\n            mask = (res[measurement_col] - mean) > stdev_thres * std\n    else:\n        if len(grouping_columns) > 0:\n\n            def f(group):\n                res = outliers_grubbs(group[measurement_col])\n                return pd.DataFrame(res, index=group.index)\n\n            outlier_tags = res.groupby(\n                grouping_columns, as_index=False, group_keys=False\n            ).apply(f)[0]\n        else:\n            outlier_tags = outliers_grubbs(res[measurement_col])\n\n        mask = outlier_tags == 1\n\n    num_outliers = mask.sum()\n\n    globals()[f\"{df_picker.key}_outliers\"] = res.loc[mask, :]\n    globals()[f\"{df_picker.key}_no_outliers\"] = res.loc[~mask, :]\n    res['is_outlier'] = mask\n    res['outlier_metric'] = res[measurement_col]\n    globals()[f\"plot_outliers\"] = res\n    outlier_signal(res.loc[~mask, :])\n\n    if num_outliers == 0:\n        w_text_output(content=\"No outliers found\", appearance={\"message_box\": \"info\"})\n    else:\n        output_strings = []\n        for index, row in res.loc[mask, :].iterrows():\n            row_string = f\"{row[target_col_signal()]}-{measurement_col}-{row[measurement_col]}\"\n            output_strings.append(row_string)\n\n        w_text_output(\n            content=f\"{num_outliers} outliers found: {', '.join(output_strings)}\", appearance={\"message_box\": \"info\"}\n        )\n\n    w_text_output(content=f\"\"\"\nThe ```{df_picker.key}_outliers``` table shows identified outliers. \nThe ```{df_picker.key}_no_outliers``` table shows your data with outliers removed. \n    \"\"\")\n\nw_text_output(content=\"\"\"\n## _(Optional)_ Outlier Removal\n\nRemove outliers with Grubb's or with a standard deviation cutoff.\n\n\"\"\")\n\noutlier_signal = Signal(None)\nf()",
      "metadata": {
        "transformId": "7073",
        "stale": false
      },
      "language": "python"
    },
    {
      "cellType": "markdown",
      "source": "## _(Optional)_  Outlier Plot\n\nIn the plot below, the outliers will be plotted in green, while retained datapoints will be shown in orange. If no outliers are identified, all points will be orange. \n\nThis plot is plotting the ```plot_outliers``` table generated above. This table has a column called ```is_outlier```, which has a True/False value for each row, denoting if that row was identied as an outlier."
    },
    {
      "plotId": "6986",
      "cellType": "plot"
    }
  ]
}